---
layout: post
comments: true
title:  "Understanding Self-Attention and the Unreasonable Effectiveness of a Transformer"
excerpt: "We'll understand the self-attention mechanism that powers Transformer neural networks and go through an example by hand to understand these concepts. You can follow along!"
date:   2025-04-11 11:00:00
mathjax: true
---

There's something magical about Recurrent Neural Networks (RNNs).